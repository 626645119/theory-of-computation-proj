
@misc{noauthor_quick_nodate,
	title = {quick start guide [{Zotero} {Documentation}]},
	url = {https://www.zotero.org/support/quick_start_guide},
	urldate = {2021-09-13},
	file = {quick start guide [Zotero Documentation]:/Users/justin/Zotero/storage/6PMFWAL6/quick_start_guide.html:text/html},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero：科研小白的第一款文献管理软件},
	url = {https://zhuanlan.zhihu.com/p/347493385},
	abstract = {2021.3.13 翻译器更新需要勾选【Enable Logging】和【Show in Console】再进行更新。随着深入使用Zotero，我认为Zotero已经成为了我个人知识管理系统的 中枢。除了基础的文献管理功能，借助Zotero我还可以联结自己…},
	language = {zh},
	urldate = {2021-09-13},
	journal = {知乎专栏},
	file = {Snapshot:/Users/justin/Zotero/storage/TVXYRV33/347493385.html:text/html},
}

@article{li_structural_2016,
	title = {Structural {Information} and {Dynamical} {Complexity} of {Networks}},
	volume = {62},
	issn = {0018-9448, 1557-9654},
	url = {http://ieeexplore.ieee.org/document/7456290/},
	doi = {10.1109/TIT.2016.2555904},
	abstract = {In 1953, Shannon proposed the question of quantiﬁcation of structural information to analyze communication systems. The question has become one of the longest great challenges in information science and computer science. Here, we propose the ﬁrst metric for structural information. Given a graph G, we deﬁne the K -dimensional structural information of G (or structure entropy of G), denoted by H K (G), to be the minimum overall number of bits required to determine the K -dimensional code of the node that is accessible from random walk in G. The K -dimensional structural information provides the principle for completely detecting the natural or true structure, which consists of the rules, regulations, and orders of the graphs, for fully distinguishing the order from disorder in structured noisy data, and for analyzing communication systems, solving the Shannon’s problem and opening up new directions. The K -dimensional structural information is also the ﬁrst metric of dynamical complexity of networks, measuring the complexity of interactions, communications, operations, and even evolution of networks. The metric satisﬁes a number of fundamental properties, including additivity, locality, robustness, local and incremental computability, and so on. We establish the fundamental theorems of the one- and two-dimensional structural information of networks, including both lower and upper bounds of the metrics of classic data structures, general graphs, the networks of models, and the networks of natural evolution. We propose algorithms to approximate the K -dimensional structural information of graphs by ﬁnding the K -dimensional structure of the graphs that minimizes the K -dimensional structure entropy. We ﬁnd that the K -dimensional structure entropy minimization is the principle for detecting the natural or true structures in real-world networks. Consequently, our structural information provides the foundation for knowledge discovering from noisy data. We establish a black hole principle by using the two-dimensional structure information of graphs. We propose the natural rank of locally listing algorithms by the structure entropy minimization principle, providing the basis for a next-generation search engine.},
	language = {en},
	number = {6},
	urldate = {2021-09-27},
	journal = {IEEE Transactions on Information Theory},
	author = {Li, Angsheng and Pan, Yicheng},
	month = jun,
	year = {2016},
	pages = {3290--3339},
	file = {Li 和 Pan - 2016 - Structural Information and Dynamical Complexity of.pdf:/Users/justin/Zotero/storage/PA2SZAUB/Li 和 Pan - 2016 - Structural Information and Dynamical Complexity of.pdf:application/pdf},
}

@article{liu_rem_nodate,
	title = {{REM}: {From} {Structural} {Entropy} to {Community} {Structure} {Deception}},
	abstract = {This paper focuses on the privacy risks of disclosing the community structure in an online social network. By exploiting the community afﬁliations of user accounts, an attacker may infer sensitive user attributes. This raises the problem of community structure deception (CSD), which asks for ways to minimally modify the network so that a given community structure maximally hides itself from community detection algorithms. We investigate CSD through an informationtheoretic lens. To this end, we propose a community-based structural entropy to express the amount of information revealed by a community structure. This notion allows us to devise residual entropy minimization (REM) as an efﬁcient procedure to solve CSD. Experimental results over 9 real-world networks and 6 community detection algorithms show that REM is very effective in obfuscating the community structure as compared to other benchmark methods.},
	language = {en},
	author = {Liu, Yiwei and Liu, Jiamou and Zhang, Zijian and Zhu, Liehuang and Li, Angsheng},
	pages = {11},
	file = {Liu 等。 - REM From Structural Entropy to Community Structur.pdf:/Users/justin/Zotero/storage/NNVKMQVY/Liu 等。 - REM From Structural Entropy to Community Structur.pdf:application/pdf},
}

@article{li_structural_2020,
	title = {Structural {Information} {Learning} {Machinery}: {Learning} from {Observing}, {Associating}, {Optimizing}, {Decoding}, and {Abstracting}},
	shorttitle = {Structural {Information} {Learning} {Machinery}},
	url = {http://arxiv.org/abs/2001.09637},
	abstract = {Both computation and information are the keys to understanding learning and intelligence. However, the studies of computation and information had been largely separated in the academic communities, for which a fundamental question in the theoretical underpinnings of information science and computer science is to measure the information that is embedded in a physical system [2]. The author and his co-author [12] introduced the notion of encoding tree as a lossless encoding of a graph and the metric of structural entropy of graphs. The structural entropy of a graph is the intrinsic information hidden in the graph that cannot be decoded by any encoding tree or any lossless encoding of the graph. The structural information is deﬁned as a concept of the merging of computation and information. In the present paper, we propose the model of structural information learning machines (SiLeM for short), leading to a mathematical deﬁnition of learning by merging the theories of computation and information. Our model shows that the essence of learning is to gain information, that to gain information is to eliminate uncertainty embedded in a data space, and that to eliminate uncertainty of a data space can be reduced to an optimization problem, that is, an information optimization problem, which can be realized by a general encoding tree method. The principle and criterion of the structural information learning machines are maximization of decoding information from the data points observed together with the relationships among the data points, and semantical interpretation of syntactical essential structure, respectively. A SiLeM machine learns the laws or rules of nature. It observes the data points of real world, builds the connections among the observed data and constructs a data space, for which the principle is to choose the way of connections of data points so that the decoding information of the data space is maximized, ﬁnds the encoding tree of the data space that minimizes the dynamical uncertainty of the data space, in which the encoding tree is hence referred to as a decoder, due to the fact that it has already eliminated the maximum amount of uncertainty embedded in the data space, interprets the semantics of the decoder, an encoding tree, to form a knowledge tree, extracts the remarkable common features for both semantical and syntactical features of the modules decoded by a decoder to construct trees of abstractions, providing the foundations for intuitive reasoning in the learning when new data are observed. Our SiLeM machines learn from observing, associating, encoding, optimizing, decoding, interpreting, abstracting and intuitive reasoning to realize the maximum gain of information, without any handmade choice of parameter.},
	language = {en},
	urldate = {2021-11-08},
	journal = {arXiv:2001.09637 [cs, math]},
	author = {Li, Angsheng},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.09637},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Theory, Computer Science - Machine Learning},
	file = {Li - 2020 - Structural Information Learning Machinery Learnin.pdf:/Users/justin/Zotero/storage/ILEFYIMH/Li - 2020 - Structural Information Learning Machinery Learnin.pdf:application/pdf},
}

@article{flood_understanding_2010,
	title = {Understanding phenomenology: \textit{{Anne} {Flood} looks at the theory and methods involved in phenomenological research}},
	volume = {17},
	issn = {1351-5578, 2047-8992},
	shorttitle = {Understanding phenomenology},
	url = {http://rcnpublishing.com/doi/abs/10.7748/nr2010.01.17.2.7.c7457},
	doi = {10.7748/nr2010.01.17.2.7.c7457},
	abstract = {Phenomenology is a philosophic attitude and research approach. Its primary position is that the most basic human truths are accessible only through inner subjectivity, and that the person is integral to the environment. This paper discusses the theoretical perspectives related to phenomenology, and includes a discussion of the methods adopted in phenomenological research.},
	language = {en},
	number = {2},
	urldate = {2021-12-17},
	journal = {Nurse Researcher},
	author = {Flood, Anne},
	month = jan,
	year = {2010},
	pages = {7--15},
	file = {Flood - 2010 - Understanding phenomenology Anne Flood looks a.pdf:/Users/justin/Zotero/storage/24SZKEIS/Flood - 2010 - Understanding phenomenology Anne Flood looks a.pdf:application/pdf},
}

@article{dowling_husserl_2007,
	title = {From {Husserl} to van {Manen}. {A} review of different phenomenological approaches},
	volume = {44},
	issn = {00207489},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020748905002506},
	doi = {10.1016/j.ijnurstu.2005.11.026},
	abstract = {This paper traces the development of phenomenology as a philosophy originating from the writings of Husserl to its use in phenomenological research and theory development in nursing. The key issues of phenomenological reduction and bracketing are also discussed as they play a pivotal role in the how phenomenological research studies are approached. What has become to be known as ‘‘new’’ phenomenology is also explored and the key differences between it and ‘‘traditional’’ phenomenology are discussed. van Manen’s phenomenology is also considered in light of its contemporary popularity among nurse researchers.},
	language = {en},
	number = {1},
	urldate = {2021-12-17},
	journal = {International Journal of Nursing Studies},
	author = {Dowling, Maura},
	month = jan,
	year = {2007},
	pages = {131--142},
	file = {Dowling - 2007 - From Husserl to van Manen. A review of different p.pdf:/Users/justin/Zotero/storage/I2668D4S/Dowling - 2007 - From Husserl to van Manen. A review of different p.pdf:application/pdf},
}

@incollection{spiegelberg_original_1994,
	address = {Dordrecht},
	title = {The {Original} {Phenomenological} {Movement}},
	isbn = {978-94-009-7491-3},
	url = {https://doi.org/10.1007/978-94-009-7491-3_5},
	abstract = {There was no such thing as a definite beginning of a Phenomenological Movement, let alone a school, in Husserl's wake, just as little as there had been a deliberate and clearly marked founding of phenomenology in his own development. But around 1905 Husserl began to attract a number of students, in the beginning chiefly from Munich, who developed a kind of group spirit and initiative which led gradually to the formation of the Göttingen Circle.},
	booktitle = {The {Phenomenological} {Movement}: {A} {Historical} {Introduction}},
	publisher = {Springer Netherlands},
	author = {Spiegelberg, Herbert},
	year = {1994},
	doi = {10.1007/978-94-009-7491-3_5},
	pages = {166--267},
}

@book{kockelmans_edmund_1994,
	title = {Edmund {Husserl}'s {Phenomenology}},
	publisher = {Purdue University Press},
	author = {Kockelmans, Joseph J. and Husserl, Edmund},
	year = {1994},
}

@article{moustakas_phenomenological_1994,
	title = {Phenomenological research: {Analyses} and examples},
	journal = {Phenomenological research methods},
	author = {Moustakas, Clark},
	year = {1994},
	note = {Publisher: Sage Publications Thousand Oaks, CA},
	pages = {120--154},
}

@book{van_manen_researching_2016,
	title = {Researching lived experience: {Human} science for an action sensitive pedagogy},
	publisher = {Routledge},
	author = {Van Manen, Max},
	year = {2016},
}

@book{moran_introduction_2002,
	title = {Introduction to phenomenology},
	publisher = {Routledge},
	author = {Moran, Dermot},
	year = {2002},
}

@article{owen_introducing_1994,
	title = {Introducing an existential-phenomenological approach: basic phenomenological theory and research–part {I}},
	volume = {7},
	number = {3},
	journal = {Counselling psychology quarterly},
	author = {Owen, Ian R},
	year = {1994},
	note = {Publisher: Taylor \& Francis},
	pages = {261--273},
}

@article{racher_are_2003,
	title = {Are phenomenology and postpositivism strange bedfellows?},
	volume = {25},
	number = {5},
	journal = {Western journal of nursing research},
	author = {Racher, Frances E and Robinson, Steven},
	year = {2003},
	note = {Publisher: SAGE Publications},
	pages = {464--481},
}

@incollection{polkinghorne_phenomenological_1989,
	title = {Phenomenological research methods},
	booktitle = {Existential-phenomenological perspectives in psychology},
	publisher = {Springer},
	author = {Polkinghorne, Donald E},
	year = {1989},
	pages = {41--60},
}

@article{crotty_doing_1996,
	title = {Doing phenomenology},
	journal = {NOTE 363p.; Produced by the University of South Australia, Centre for Research in Education, Equity and Work. Grant towards production provided by Texts in Humanities, School of Education, University of South Australia. Papers from},
	author = {Crotty, Michael and Willis, P and Neville, B},
	year = {1996},
	note = {Publisher: ERIC},
	pages = {274},
}

@article{li_resistance_2017,
	title = {Resistance maximization principle for defending networks against virus attack},
	volume = {466},
	issn = {03784371},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437116306252},
	doi = {10.1016/j.physa.2016.09.009},
	abstract = {We investigate the defending of networks against virus attack. We define the resistance of a network to be the maximum number of bits required to determine the code of the module that is accessible from random walk, from which random walk cannot escape. We show that for any network G, R(G) = H 1(G) − H 2(G), where R(G) is the resistance of G, H 1(G) and H 2(G) are the one- and two-dimensional structural information of G, respectively, and that resistance maximization is the principle for defending networks against virus attack. By using the theory, we investigate the defending of real world networks and of the networks generated by the preferential attachment and the security models. We show that there exist networks that are defensible by a small number of controllers from cascading failure of any virus attack. Our theory demonstrates that resistance maximization is the principle for defending networks against virus attacks.},
	language = {en},
	urldate = {2021-12-20},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Li, Angsheng and Zhang, Xiaohui and Pan, Yicheng},
	month = jan,
	year = {2017},
	pages = {211--223},
	file = {Li 等。 - 2017 - Resistance maximization principle for defending ne.pdf:/Users/justin/Zotero/storage/6E4R4XBD/Li 等。 - 2017 - Resistance maximization principle for defending ne.pdf:application/pdf},
}

@inproceedings{ribeiro_struc2vec_2017,
	address = {Halifax NS Canada},
	title = {\textit{struc2vec}: {Learning} {Node} {Representations} from {Structural} {Identity}},
	isbn = {978-1-4503-4887-4},
	shorttitle = {\textit{struc2vec}},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098061},
	doi = {10.1145/3097983.3098061},
	abstract = {Structural identity is a concept of symmetry in which network nodes are identi ed according to the network structure and their relationship to other nodes. Structural identity has been studied in theory and practice over the past decades, but only recently has it been addressed with representational learning techniques. is work presents struc2vec, a novel and exible framework for learning latent representations for the structural identity of nodes. struc2vec uses a hierarchy to measure node similarity at di erent scales, and constructs a multilayer graph to encode structural similarities and generate structural context for nodes. Numerical experiments indicate that state-of-the-art techniques for learning node representations fail in capturing stronger notions of structural identity, while struc2vec exhibits much superior performance in this task, as it overcomes limitations of prior approaches. As a consequence, numerical experiments indicate that struc2vec improves performance on classi cation tasks that depend more on structural identity.},
	language = {en},
	urldate = {2021-12-23},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ribeiro, Leonardo F.R. and Saverese, Pedro H.P. and Figueiredo, Daniel R.},
	month = aug,
	year = {2017},
	pages = {385--394},
	file = {Ribeiro 等。 - 2017 - struc2vec Learning Node Representations fr.pdf:/Users/justin/Zotero/storage/UB4VCLWG/Ribeiro 等。 - 2017 - struc2vec Learning Node Representations fr.pdf:application/pdf},
}

@inproceedings{andersen_local_2006,
	address = {Berkeley, CA, USA},
	title = {Local {Graph} {Partitioning} using {PageRank} {Vectors}},
	isbn = {978-0-7695-2720-8},
	url = {http://ieeexplore.ieee.org/document/4031383/},
	doi = {10.1109/FOCS.2006.44},
	abstract = {A local graph partitioning algorithm ﬁnds a cut near a speciﬁed starting vertex, with a running time that depends largely on the size of the small side of the cut, rather than the size of the input graph. In this paper, we present a local partitioning algorithm using a variation of PageRank with a speciﬁed starting distribution. We derive a mixing result for PageRank vectors similar to that for random walks, and show that the ordering of the vertices produced by a PageRank vector reveals a cut with small conductance. In particular, we show that for any set C with conductance Φ and volume k, a PageRank vector with a certain starting distributi√on can be used to produce a set with conductance O( Φ log k). We present an improved algorithm for computing approximate PageRank vectors, which allows us to ﬁnd such a set in time proportional to its size. In particular, we can ﬁnd a cut with conductance at most φ, whose small side has volume at least 2b, in time O(2b log2 m/φ2) where m is the number of edges in the graph. By combining small sets found by this local partitioning algorithm, we obtain a cut with conductance φ and approximately optimal balance in time O(m log4 m/φ2).},
	language = {en},
	urldate = {2021-12-23},
	booktitle = {2006 47th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS}'06)},
	publisher = {IEEE},
	author = {Andersen, Reid and Chung, Fan and Lang, Kevin},
	year = {2006},
	pages = {475--486},
	file = {Andersen 等。 - 2006 - Local Graph Partitioning using PageRank Vectors.pdf:/Users/justin/Zotero/storage/XUQSXRVT/Andersen 等。 - 2006 - Local Graph Partitioning using PageRank Vectors.pdf:application/pdf},
}

@article{wang_survey_nodate,
	title = {A {Survey} on {Heterogeneous} {Graph} {Embedding}: {Methods}, {Techniques}, {Applications} and {Sources}},
	abstract = {Heterogeneous graphs (HGs) also known as heterogeneous information networks have become ubiquitous in real-world scenarios; therefore, HG embedding, which aims to learn representations in a lower-dimension space while preserving the heterogeneous structures and semantics for downstream tasks (e.g., node/graph classiﬁcation, node clustering, link prediction), has drawn considerable attentions in recent years. In this survey, we perform a comprehensive review of the recent development on HG embedding methods and techniques. We ﬁrst introduce the basic concepts of HG and discuss the unique challenges brought by the heterogeneity for HG embedding in comparison with homogeneous graph representation learning; and then we systemically survey and categorize the state-of-the-art HG embedding methods based on the information they used in the learning process to address the challenges posed by the HG heterogeneity. In particular, for each representative HG embedding method, we provide detailed introduction and further analyze its pros and cons; meanwhile, we also explore the transformativeness and applicability of different types of HG embedding methods in the real-world industrial environments for the ﬁrst time. In addition, we further present several widely deployed systems that have demonstrated the success of HG embedding techniques in resolving real-world application problems with broader impacts. To facilitate future research and applications in this area, we also summarize the open-source code, existing graph learning platforms and benchmark datasets. Finally, we explore the additional issues and challenges of HG embedding and forecast the future research directions in this ﬁeld.},
	language = {en},
	author = {Wang, Xiao and Bo, Deyu and Shi, Chuan and Fan, Shaohua and Ye, Yanfang and Yu, Philip S},
	pages = {20},
	file = {Wang 等。 - A Survey on Heterogeneous Graph Embedding Methods.pdf:/Users/justin/Zotero/storage/UCZQJV79/Wang 等。 - A Survey on Heterogeneous Graph Embedding Methods.pdf:application/pdf},
}

@article{zhang_automated_2021,
	title = {Automated {Machine} {Learning} on {Graphs}: {A} {Survey}},
	shorttitle = {Automated {Machine} {Learning} on {Graphs}},
	url = {http://arxiv.org/abs/2103.00742},
	doi = {10.24963/ijcai.2021/637},
	abstract = {Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difﬁcult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attention from the research community. Therefore, we comprehensively survey AutoML on graphs in this paper1, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in-depth discuss AutoGL, the ﬁrst dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. This paper is the ﬁrst systematic and comprehensive review of automated machine learning on graphs to the best of our knowledge.},
	language = {en},
	urldate = {2021-12-23},
	journal = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence},
	author = {Zhang, Ziwei and Wang, Xin and Zhu, Wenwu},
	month = aug,
	year = {2021},
	note = {arXiv: 2103.00742},
	keywords = {Computer Science - Machine Learning},
	pages = {4704--4712},
	file = {Zhang 等。 - 2021 - Automated Machine Learning on Graphs A Survey.pdf:/Users/justin/Zotero/storage/BVZRVW3N/Zhang 等。 - 2021 - Automated Machine Learning on Graphs A Survey.pdf:application/pdf},
}

@article{mandal_meta-learning_2021,
	title = {Meta-{Learning} with {Graph} {Neural} {Networks}: {Methods} and {Applications}},
	shorttitle = {Meta-{Learning} with {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2103.00137},
	abstract = {Graph Neural Networks (GNNs), a generalization of deep neural networks on graph data have been widely used in various domains, ranging from drug discovery to recommender systems. However, GNNs on such applications are limited when there are few available samples. Meta-learning has been an important framework to address the lack of samples in machine learning, and in recent years, the researchers have started to apply meta-learning to GNNs. In this work, we provide a comprehensive survey of different meta-learning approaches involving GNNs on various graph problems showing the power of using these two approaches together. We categorize the literature based on proposed architectures, shared representations, and applications. Finally, we discuss several exciting future research directions and open problems.},
	language = {en},
	urldate = {2021-12-23},
	journal = {arXiv:2103.00137 [cs]},
	author = {Mandal, Debmalya and Medya, Sourav and Uzzi, Brian and Aggarwal, Charu},
	month = nov,
	year = {2021},
	note = {arXiv: 2103.00137},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Mandal 等。 - 2021 - Meta-Learning with Graph Neural Networks Methods .pdf:/Users/justin/Zotero/storage/8ZBYAHAJ/Mandal 等。 - 2021 - Meta-Learning with Graph Neural Networks Methods .pdf:application/pdf},
}

@article{liu_graph_2021,
	title = {Graph {Self}-{Supervised} {Learning}: {A} {Survey}},
	shorttitle = {Graph {Self}-{Supervised} {Learning}},
	url = {http://arxiv.org/abs/2103.00111},
	abstract = {Deep learning on graphs has attracted signiﬁcant interests recently. However, most of the works have focused on (semi-) supervised learning, resulting in shortcomings including heavy label reliance, poor generalization, and weak robustness. To address these issues, self-supervised learning (SSL), which extracts informative knowledge through well-designed pretext tasks without relying on manual labels, has become a promising and trending learning paradigm for graph data. Different from SSL on other domains like computer vision and natural language processing, SSL on graphs has an exclusive background, design ideas, and taxonomies. Under the umbrella of graph self-supervised learning, we present a timely and comprehensive review of the existing approaches which employ SSL techniques for graph data. We construct a uniﬁed framework that mathematically formalizes the paradigm of graph SSL. According to the objectives of pretext tasks, we divide these approaches into four categories: generation-based, auxiliary property-based, contrast-based, and hybrid approaches. We further describe the applications of graph SSL across various research ﬁelds and summarize the commonly used datasets, evaluation benchmark, performance comparison and open-source codes of graph SSL. Finally, we discuss the remaining challenges and potential future directions in this research ﬁeld.},
	language = {en},
	urldate = {2021-12-23},
	journal = {arXiv:2103.00111 [cs]},
	author = {Liu, Yixin and Jin, Ming and Pan, Shirui and Zhou, Chuan and Xia, Feng and Yu, Philip S.},
	month = dec,
	year = {2021},
	note = {arXiv: 2103.00111},
	keywords = {Computer Science - Machine Learning},
	file = {Liu 等。 - 2021 - Graph Self-Supervised Learning A Survey.pdf:/Users/justin/Zotero/storage/FC8VI6AS/Liu 等。 - 2021 - Graph Self-Supervised Learning A Survey.pdf:application/pdf},
}
@article{lieberman2009comprehensive,
  title={Comprehensive mapping of long-range interactions reveals folding principles of the human genome},
  author={Lieberman-Aiden, Erez and Van Berkum, Nynke L and Williams, Louise and Imakaev, Maxim and Ragoczy, Tobias and Telling, Agnes and Amit, Ido and Lajoie, Bryan R and Sabo, Peter J and Dorschner, Michael O and others},
  journal={science},
  volume={326},
  number={5950},
  pages={289--293},
  year={2009},
  publisher={American Association for the Advancement of Science}
}
@article{dixon2012topological,
  title={Topological domains in mammalian genomes identified by analysis of chromatin interactions},
  author={Dixon, Jesse R and Selvaraj, Siddarth and Yue, Feng and Kim, Audrey and Li, Yan and Shen, Yin and Hu, Ming and Liu, Jun S and Ren, Bing},
  journal={Nature},
  volume={485},
  number={7398},
  pages={376--380},
  year={2012},
  publisher={Nature Publishing Group}
}
@article{filippova2014identification,
  title={Identification of alternative topological domains in chromatin},
  author={Filippova, Darya and Patro, Rob and Duggal, Geet and Kingsford, Carl},
  journal={Algorithms for Molecular Biology},
  volume={9},
  number={1},
  pages={1--11},
  year={2014},
  publisher={Springer}
}
@incollection{dhillon2001efficient,
  title={Efficient clustering of very large document collections},
  author={Dhillon, Inderjit S and Fan, James and Guan, Yuqiang},
  booktitle={Data mining for scientific and engineering applications},
  pages={357--381},
  year={2001},
  publisher={Springer}
}
@inproceedings{dhillon2003information,
  title={Information-theoretic co-clustering},
  author={Dhillon, Inderjit S and Mallela, Subramanyam and Modha, Dharmendra S},
  booktitle={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={89--98},
  year={2003}
}
@inproceedings{xu2003document,
  title={Document clustering based on non-negative matrix factorization},
  author={Xu, Wei and Liu, Xin and Gong, Yihong},
  booktitle={Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
  pages={267--273},
  year={2003}
}
@inproceedings{long2005co,
  title={Co-clustering by block value decomposition},
  author={Long, Bo and Zhang, Zhongfei and Yu, Philip S},
  booktitle={Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining},
  pages={635--640},
  year={2005}
}
@inproceedings{guha2004propagation,
  title={Propagation of trust and distrust},
  author={Guha, Ramanthan and Kumar, Ravi and Raghavan, Prabhakar and Tomkins, Andrew},
  booktitle={Proceedings of the 13th international conference on World Wide Web},
  pages={403--412},
  year={2004}
}
@article{li2015discovering,
  title={Discovering natural communities in networks},
  author={Li, Angsheng and Li, Jiankou and Pan, Yicheng},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={436},
  pages={878--896},
  year={2015},
  publisher={Elsevier}
}
